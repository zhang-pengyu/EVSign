<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>EvSign: Sign Language Recognition and Translation with Streaming Events</title>
  <!--=================Meta tags==========================-->
  <meta name="robots" content="index,follow">
  <meta name="description"
    content="Project page for ECCV 2024 -- EvSign: Sign Language Recognition and Translation with Streaming Events">
  <meta name="keywords" content="EVSign, Sign language recognition, Sign language translation, event camera">
  <link rel="author" href="https://github.com/zhang-pengyu">
  <!--=================js==========================-->
  <link href="./css.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="main.css" media="screen">
  <script src="./effect.js "></script>
  <!-- Latex -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
      </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>
  <!--=================Google Analytics==========================-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129775907-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-129775907-1');
  </script>
</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
        <h1>
          <font color="red">E</font><font color="blue">v</font>Sign: Sign Language Recognition and Translation <br> with Streaming Events
        </h1>

        <!--=================Authors==========================-->
        <div class="authors">
          <a href="https://pengyuzhang.me/" target="_blank">Pengyu Zhang</a> <sup>1,2</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="" target="_blank">Hao Yin</a> <sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="" target="_blank">Zeren Wang</a> <sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="" target="_blank">Wenyue Chen</a> <sup>1</sup> <br>
          <a href="" target="_blank">Shengming Li</a> <sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://github.com/wangdongdut" target="_blank">Dong Wang</a> <sup>1</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://scholar.google.com.hk/citations?user=D3nE0agAAAAJ" target="_blank">Huchuan Lu</a>
          <sup>1,3</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://stephenjia.github.io/"target="_blank">Xu Jia</a> <sup>1</sup>
        </div>

        <div class="affiliations ">
          <sup>1</sup> IIAU, Dalian University of Technology &nbsp;
          <sup>2</sup> National University of Singapore &nbsp;
          <sup>3</sup> Peng Cheng Laboratory &nbsp;
        </div>
       
<!--=================Tabs==========================-->
        <ul id="tabs">
          <li><a href="#Highlights" name="#tab1">Highlights</a></li>
          <li><a href="#Download" name="#tab2">Download</a></li>
          <li><a href="#Evaluation & Results" name="#tab3">Evaluation & Results</a></li>
          <li><a href="#Citation" name="#tab4">Citation</a></li>
          <li><a href="#Contact" name="#tab5">Contact</a></li>
      </div>
      <br>
      <!--=================Teasers==========================-->
      <div id="img_intro_examples" class="img_container">
        <center><video width="320" height="240" controls>
      <source src="./overview.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></center>
      </div>
       <!--=================News==========================-->
      <div class="section Highlights", id="Highlights">
        <h2><font color="red">News</font></h2>
        <ol>
          <li><strong>7/12/2024</strong>: The EvSign dataset is released at Google drive and Baidu disk. </li>
          <li><strong>7/1/2024</strong>: The EvSign dataset is accepted by ECCV 2024. </li>
        </ol>
      </div>
      
      <!--=================Abstract==========================-->
      <div class="section abstract">
        <h2>Abstract</h2>
        <br>
        <p style="text-align:justify">
          Sign language is one of the most effective communication tools for people with hearing difficulties. Most existing works focus on improving the performance of sign language tasks on RGB videos, which may suffer from degraded recording conditions, such as 
          fast movement of hands with motion blur and textured signer's appearance. The bio-inspired event camera, which asynchronously captures brightness change with high speed, could naturally perceive dynamic hand movements, providing rich manual clues for sign 
          language tasks. In this work, we aim at exploring the potential of event camera in continuous sign language recognition~(CSLR) and sign language translation~(SLT). To promote the research, we first collect an event-based benchmark EvSignbfor those tasks 
          with both gloss and spoken language annotations. EvSign dataset offers a substantial amount of high-quality event streams and an extensive vocabulary of glosses and words, thereby facilitating the development of sign language tasks. In addition, we propose 
          an efficient transformer-based framework for event-based SLR and SLT tasks, which fully leverages the advantages of streaming events. The sparse backbone is employed to extract visual features from sparse events. Then, the temporal coherence is effectively 
          utilized through the proposed local token fusion and gloss-aware temporal aggregation modules. Extensive experimental results are reported on both simulated~(PHOENIX14T) and EvSign datasets. Our method performs favorably against existing state-of-the-art 
          approaches with only 0.34% computational cost (0.84G FLOPS per video) and 44.2% network parameters.
        </p>
      </div>

      <!--=================Downloads==========================-->
      <div class="section" , id="Download">
        <h2>Download</h2>
          <h3> <font color="FireBrick">Event data </font></h3>
          <table>
            <tbody>
              <tr>
                <td><font color="FireBrick">Raw event</td>
                <td><a href="https://pan.baidu.com/s/1sRSccxFeHDziMlMdnEZUMA?pwd=1utj">Baidu disk</a></td>
                <td><a href="https://drive.google.com/drive/folders/1GwYNPcrkUM-gVDAObxNqERi_2Db7okjP?usp=sharing">Google drive</a></td>
              </tr>
              <tr>
                <td><font color="FireBrick">Voxel grid</td>
                <td><a href="https://pan.baidu.com/s/1u6isRimdR18jZYajByYK-A?pwd=mqs8">Baidu disk</a></td>
                <td><a href="https://drive.google.com/drive/folders/1GhYvrx2VJtFVSRz0dvKhW-oI7M1MOs-a?usp=sharing">Google drive</a></td>
              </tr>
              <tr>
                <td><font color="FireBrick">Annotations</td>
                <td><a href="https://pan.baidu.com/s/1BL8TrrnLifT-REJRVyJeNA?pwd=ltnd">Baidu disk</a></td>
                <td><a href="https://drive.google.com/drive/folders/11E-WPkCPVL49hOKRdCzfgQULmGU8pyz8?usp=sharing">Google drive</a></td>
              </tr>
              </tbody>
          </table>
          <h3> <font color="FireBrick">RGB data </font></h3>
          <i>RGB data is comming soon.</i>
      </div>
        
      <!--=================Citation==========================-->
      <div class="section Citation" , id="Citation">
        <h2>Citation</h2>
        <div class="section bibtex">
          <pre>@InProceedings{Zhang_ECCV24_EvSign,
          author = {Zhang Pengyu and Hao Yin and Zeren Wang and Wenyue Chen 
            and Shengming Li and Dong Wang and Huchuan Lu and Xu Jia},
          title = {EvSign: Sign Language Recognition and Translation with Streaming Events},
          booktitle = {European Conference on Computer Vision},
          year = {2024}}
          </pre>
        </div>
     </div>
      <!--=================Contact==========================-->
      <div class="section contact", id="Contact">
        <h2 id="contact">Contact</h2>
        <p style="text-align:justify">If you have any question, please contact Pengyu Zhang at
          <strong>zpy.iiau@gmail.com</strong>.</p>
      </div>
</body>

</html>
